---
title: "Hello!"
layout: single
permalink: /
---

I'm a 2nd year PhD student in Computer Science at the [University of Washington](https://www.cs.washington.edu/), and a visiting researcher at [Facebook AI Research](https://ai.facebook.com/). I'm advised by [Noah Smith](https://nasmith.github.io/) and [Luke Zettlemoyer](https://www.cs.washington.edu/people/faculty/lsz).

I was previously a Predoctoral Young Investigator at [AI2](http://allenai.org), and a data scientist and software engineer in startups in Boston and Seattle. And in another world, I did research in [neuroscience](#neuroscience)!


I do research in natural language processing and machine learning. My main research interests are:

 * <span style="color:#add8e6"><i class="fas fa-wind"></i></span> Adaptive and rapidly customizable [**language models**](#adaptive-language-models)
 * <span style="color:#daa520"><i class="fas fa-shield-alt"></i></span>  [**Safety and ethics**](#safety-and-ethics) of language models
 * <span style="color:#32cd77"><i class="fas fa-leaf"></i></span> [**Green NLP**](#green-nlp)
 * <span style="color:#ff0088"><i class="fas fa-sort-amount-down"></i></span> Improving [**Model Evaluation**](#evaluation)

## Adaptive Language Models
ðŸ’« **New paper** ðŸ’«<br>*DEMix Layers: Disentangling Domains for Modular Language Modeling*
<br><sub>with [Mike Lewis](https://twitter.com/ml_perception?lang=en), [Ari Holtzman](https://ari-holtzman.github.io/), [Noah A. Smith](https://nasmith.github.io/), and [Luke Zettlemoyer](https://www.cs.washington.edu/people/faculty/lsz)</sub>
<br><sub> In submission // [[paper](https://arxiv.org/abs/2108.05036)] [[model code](https://github.com/kernelmachine/demix)] [[data code](https://github.com/kernelmachine/demix-data)]</sub>

*Don't Stop Pretraining: Adapt Language Models to Domains and Tasks*
<br><sub>with [Ana MarasoviÄ‡](https://www.anamarasovic.com/), [Swabha Swayamdipta](https://swabhs.com/), [Kyle Lo](https://kyleclo.github.io/), [Iz Beltagy](https://beltagy.net/), [Doug Downey](https://users.cs.northwestern.edu/~ddowney/), and [Noah A. Smith](https://nasmith.github.io/) </sub>
<br><sub>ACL 2020 // [[paper](https://aclanthology.org/2020.acl-main.740/)] [[code](https://github.com/allenai/dont-stop-pretraining)]</sub>
<br><sub>ðŸ”¥ **Honorable Mention for Best Overall Paper** ðŸ”¥</sub>

## Safety and Ethics

*RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models*
<br><sub>with [Sam Gehman](https://github.com/thesamuel), [Maarten Sap](https://homes.cs.washington.edu/~msap/), [Yejin Choi](https://homes.cs.washington.edu/~yejin/), and [Noah A. Smith](https://nasmith.github.io/)</sub>
<br><sub>EMNLP Findings 2020 //  [[paper](https://aclanthology.org/2020.findings-emnlp.301/)] [[code](https://github.com/allenai/real-toxicity-prompts)]</sub>
<br><sub>Press: [[Wired](https://www.wired.com/story/ai-fueled-dungeon-game-got-much-darker/)] [[IEEE](https://spectrum.ieee.org/open-ais-powerful-text-generating-tool-is-ready-for-business)] [[GeekWire](https://www.geekwire.com/2021/curse-neural-toxicity-ai2-uw-researchers-help-computers-watch-language/)][[Nature](https://www.nature.com/articles/d41586-021-00530-0)]</sub>

*Detoxifying Language Models Risks Marginalizing Minority Voices*
<br><sub>with [Albert Xu](https://albertxu.xyz/), [Eshaan Pathak](https://www.linkedin.com/in/eshaan-pathak/), [Eric Wallace](https://www.ericswallace.com/), [Maarten Sap](https://homes.cs.washington.edu/~msap/), and [Dan Klein](https://people.eecs.berkeley.edu/~klein/)</sub>
<br><sub>NAACL 2021 // [[paper](https://aclanthology.org/2021.naacl-main.190/)]</sub>

## Green NLP

ðŸ’« **New paper** ðŸ’«<br>*Expected Validation Performance and Estimation of a Random Variable's Maximum*
<br><sub>with [Jesse Dodge](http://www.cs.cmu.edu/~jessed/), [Roy Schwartz](https://schwartz-lab-huji.github.io/), [Dallas Card](https://web.stanford.edu/~dcard/), and [Noah A. Smith](https://nasmith.github.io/)</sub>
<br><sub>Paper and code on it's way!</sub>


*Variational Pretraining for Semi-supervised Text Classification*
<br><sub>with [Tam Dang](https://tamdang.io/), [Dallas Card](https://web.stanford.edu/~dcard/), and [Noah A. Smith](https://nasmith.github.io/)</sub>
<br><sub>ACL 2019 // [[paper](https://aclanthology.org/P19-1590/)] [[code](https://github.com/allenai/vampire)]</sub>


*Show Your Work: Improved Reporting of Experimental Results*
<br><sub>with [Jesse Dodge](http://www.cs.cmu.edu/~jessed/), [Roy Schwartz](https://schwartz-lab-huji.github.io/), [Dallas Card](https://web.stanford.edu/~dcard/), and [Noah A. Smith](https://nasmith.github.io/)</sub>
<br><sub>EMNLP 2019 // [[paper](https://aclanthology.org/D19-1224/)] [[code](https://github.com/allenai/allentune)]</sub>
<br><sub>Press: [[Wired](https://www.wired.com/story/artificial-intelligence-confronts-reproducibility-crisis/)]</sub>
<br><sub>Basis for the [Reproducibility Checklist](https://2020.emnlp.org/call-for-papers) of major NLP conferences</sub>

## Evaluation


*Annotation Artifacts in Natural Language Inference Data*
<br><sub>with [Swabha Swayamdipta](https://swabhs.com/), [Omer Levy](https://www.cs.tau.ac.il/~levyomer/), [Roy Schwartz](https://schwartz-lab-huji.github.io/), [Samuel Bowman](https://cims.nyu.edu/~sbowman/), and [Noah A. Smith](https://nasmith.github.io/)</sub>
<br><sub>NAACL 2018 // [[paper](https://aclanthology.org/N18-2017/)]</sub>

*All That's 'Human' Is Not Gold: Evaluating Human Evaluation of Generated Text*
<br><sub>with [Elizabeth Clark](https://homes.cs.washington.edu/~eaclark7/), [Tal August](https://homes.cs.washington.edu/~taugust/), Sofia Serrano, Nikita Haduong, and [Noah A. Smith](https://nasmith.github.io/)</sub>
<br><sub>ACL 2021 // [[paper](https://aclanthology.org/2021.acl-long.565/)]</sub>
<br><sub>ðŸ”¥ **Outstanding Paper Award** ðŸ”¥</sub>


## Neuroscience

*Analysis of Graph Invariants in Functional Neocortical Circuitry Reveals Generalized Features Common to Three Areas of Sensory Cortex*
<br><sub>with Alex Sadovsky and Jason Maclean</sub>
<br><sub> PLOS Comp Bio 2014 // [[paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003710)]</sub>


*Emergent coordination underlying learning to reach to grasp with a brain-machine interface*
<br><sub> with many authors ðŸ™‚</sub>
<br><sub>Journal of Neurophys 2019 // [[paper](https://pubmed.ncbi.nlm.nih.gov/29357477)]</sub>
